{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Modal Model Training - Dependent Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, AdamW\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, RandomSampler, SequentialSampler, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Smears', 'Loaded Language', 'Name calling/Labeling', 'Glittering generalities (Virtue)',\n",
    "               'Appeal to (Strong) Emotions', 'Appeal to fear/prejudice', 'Transfer', 'Doubt',\n",
    "               'Exaggeration/Minimisation', 'Whataboutism', 'Slogans', 'Flag-waving',\n",
    "               \"Misrepresentation of Someone's Position (Straw Man)\", 'Causal Oversimplification',\n",
    "               'Thought-terminating clich√©', 'Black-and-white Fallacy/Dictatorship', 'Appeal to authority',\n",
    "               'Reductio ad hitlerum', 'Repetition', 'Obfuscation, Intentional vagueness, Confusion',\n",
    "               'Presenting Irrelevant Data (Red Herring)', 'Bandwagon']\n",
    "\n",
    "### Create Class Binarizer\n",
    "one_hot = MultiLabelBinarizer()\n",
    "one_hot.fit([classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomLoader import MultiModalLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = MultiModalLoader(json_file = 'MultiModal_training_data.json', root_dir = 'Images',\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Resize(size = (224,224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ### Pixel range [-1,1]\n",
    "                           ]))\n",
    "\n",
    "testing_data = MultiModalLoader(json_file = 'MultiModal_testing_data.json', root_dir = 'Images',\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Resize(size = (224,224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ### Pixel range [-1,1]\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = training_data, batch_size = 25, shuffle = True)\n",
    "test_loader = DataLoader(dataset = testing_data, batch_size = 25, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_lower_case = True\n",
    "model_type = 'distilbert'\n",
    "model_version = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define DistilBert Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertClass(nn.Module): ### INCLUDE TOKENIZER IN CLASS\n",
    "    def __init__(self):\n",
    "        super(DistilBertClass, self).__init__()\n",
    "        \n",
    "        ### Import DistilBert Model\n",
    "        distilbert = transformers.DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in distilbert.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        ### DistilBert encoder\n",
    "        self.distil = distilbert\n",
    "                        \n",
    "            \n",
    "        self.pre_classifier = nn.Linear(770, 3072) #768\n",
    "        \n",
    "        self.fc2 = nn.Linear(3072, 1024)    \n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 128)\n",
    "        \n",
    "#         self.classifier = nn.Linear(128, 22)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.01) #.3\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, hate, sent):\n",
    "\n",
    "        ### Run DistilBert\n",
    "        distil_output = self.distil(input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "        ### Grab hidden state\n",
    "        hidden_state = distil_output[0]\n",
    "        x1 = hidden_state[:, 0]\n",
    "        \n",
    "\n",
    "        # prepare hidden state to append additional features (hate and sentiment; hotencoded)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        \n",
    "        ### Bring in hate and sentiment\n",
    "        x2 = hate\n",
    "        x3 = sent\n",
    "\n",
    "        ### Concatenate hidden state, hate, and sentiment\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "\n",
    "        ### Run through linear layers\n",
    "        fc_output = x\n",
    "        fc_output = self.pre_classifier(fc_output)\n",
    "\n",
    "        fc_output = nn.GELU()(fc_output)\n",
    "        fc_output = self.dropout(fc_output)\n",
    "\n",
    "        fc_output = self.fc2(fc_output)\n",
    "        fc_output = nn.GELU()(fc_output)\n",
    "        fc_output = self.dropout(fc_output)\n",
    "\n",
    "        #GELU\n",
    "\n",
    "        fc_output = self.fc3(fc_output)\n",
    "        fc_output = nn.GELU()(fc_output)\n",
    "        fc_output = self.dropout(fc_output)\n",
    "\n",
    "\n",
    "        fc_output = self.fc4(fc_output)\n",
    "        fc_output = nn.Tanh()(fc_output)  # using gelu except for the last one to allow for classification\n",
    "        fc_output = self.dropout(fc_output)\n",
    "\n",
    "#         output = self.classifier(fc_output)\n",
    "\n",
    "\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN-RNN-DB Architectures (Set Hidden Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet18_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(ResNet18_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet18 = models.resnet18(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = resnet18.fc.in_features\n",
    "        \n",
    "        ### Freeze Parameters\n",
    "        for param in resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        ### CNN Encoder, remove prediction layer\n",
    "        self.cnn = nn.Sequential(*list(resnet18.children())[:-1])\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size + 128, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images, distil_emb):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)   \n",
    "        \n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        ### Concatenate DistilBert embeddings\n",
    "        emb = torch.cat((image_emb, distil_emb), dim=1)\n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet50_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(ResNet50_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet50 = models.resnet50(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = resnet50.fc.in_features\n",
    "        \n",
    "        for param in resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = nn.Sequential(*list(resnet50.children())[:-1])\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)    \n",
    "        \n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet101-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet101_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(ResNet101_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet101 = models.resnet101(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = resnet101.fc.in_features\n",
    "        \n",
    "        for param in resnet101.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = nn.Sequential(*list(resnet101.children())[:-1])\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet121-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet121_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(DenseNet121_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet121 = models.densenet121(pretrained = True)\n",
    "    \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 50176 # densenet121.classifier.in_features\n",
    "        \n",
    "        for param in densenet121.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "        ### CNN Encoder\n",
    "        self.cnn = nn.Sequential(*list(densenet121.children())[:-1])\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)\n",
    "        \n",
    "        image_emb = torch.flatten(image_emb, 1)\n",
    "#         self.cnn_output_size = image_emb.shape[0]\n",
    "        \n",
    "        \n",
    "#         image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "\n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet169-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet169_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(DenseNet169_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet169 = models.densenet169(pretrained = True)\n",
    "    \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 81536 # densenet169.classifier.in_features\n",
    "        \n",
    "        for param in densenet169.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "        ### CNN Encoder\n",
    "        self.cnn = nn.Sequential(*list(densenet169.children())[:-1])\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)\n",
    "        \n",
    "        image_emb = torch.flatten(image_emb, 1)\n",
    "        \n",
    "#         image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "           \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet201-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet201_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(DenseNet201_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "               \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet201 = models.densenet201(pretrained = True)\n",
    "    \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 94080 #densenet201.classifier.in_features\n",
    "        \n",
    "        \n",
    "        for param in densenet201.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "        ### CNN Encoder\n",
    "        self.cnn = nn.Sequential(*list(densenet201.children())[:-1])\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)\n",
    "        \n",
    "        \n",
    "        image_emb = torch.flatten(image_emb, 1)\n",
    "        \n",
    "#         image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG11_BN-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG11_BN_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(VGG11_BN_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg11bn = models.vgg11_bn(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = vgg11bn.classifier[6].in_features\n",
    "        \n",
    "       \n",
    "        for param in vgg11bn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        \n",
    "        vgg11bn.classifier = nn.Sequential(*list(vgg11bn.classifier.children())[:-1])\n",
    "        \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg11bn\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16_BN-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG16_BN_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(VGG16_BN_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg16bn = models.vgg16_bn(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = vgg16bn.classifier[6].in_features\n",
    "        \n",
    "        for param in vgg16bn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        \n",
    "        vgg16bn.classifier = nn.Sequential(*list(vgg16bn.classifier.children())[:-1])\n",
    "\n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg16bn\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19_BN-LSTM-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG19_BN_LSTM_DB(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(VGG19_BN_LSTM_DB, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg19bn = models.vgg19_bn(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = vgg19bn.classifier[6].in_features\n",
    "        \n",
    "        for param in vgg19bn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        \n",
    "        vgg19bn.classifier = nn.Sequential(*list(vgg19bn.classifier.children())[:-1])\n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg19bn\n",
    "        \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optim):\n",
    "    for param_group in optim.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function is used to train a cnn model\n",
    "def Kfold_train_CNN_RNN_DB(CNN = None, DistilBert = None, training_data = None, learning_rate = None, k_folds = None, n_epochs = None, model_name = None):\n",
    "    \n",
    "    ### Check that all entries are valid\n",
    "    if ((CNN == None) or (training_data == None) or (model_name == None) or \n",
    "        (learning_rate == None) or (k_folds == None) or (n_epochs == None) or (DistilBert == None)):\n",
    "        print ('Enter all info.')\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Run K-Fold CV\n",
    "    else:\n",
    "        \n",
    "        device = 'cpu'\n",
    "\n",
    "        ### Set Loss Function and Optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        \n",
    "        #### Define the K-fold Cross Validator\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### Create values to hold the best model metrics across folds\n",
    "        val_f1_mic_max = 0 ### This determines best model\n",
    "        \n",
    "        best_train_loss = 0\n",
    "        best_train_acc = 0\n",
    "        best_train_f1_mic = 0\n",
    "        best_train_f1_mac = 0\n",
    "        best_train_prec_mic = 0\n",
    "        best_train_prec_mac = 0\n",
    "        best_train_rec_mic = 0\n",
    "        best_train_rec_mac = 0\n",
    "\n",
    "        best_val_acc = 0\n",
    "        best_val_loss = 0\n",
    "#         best_val_f1_mic = 0\n",
    "        best_val_f1_mac = 0\n",
    "        best_val_prec_mic = 0\n",
    "        best_val_prec_mac = 0\n",
    "        best_val_rec_mic = 0\n",
    "        best_val_rec_mac = 0\n",
    "        \n",
    "        best_fold = 0\n",
    "        best_epoch = 0\n",
    "        \n",
    "\n",
    "        \n",
    "        ### Start print\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        ### K-fold Cross Validation model evaluation\n",
    "        for fold, (train_ids, val_ids) in enumerate(kfold.split(training_data)):\n",
    "            \n",
    "            print('-------------------------------------------')\n",
    "            print('FOLD {}'.format(fold + 1))\n",
    "            print('-------------------------------------------')\n",
    "            \n",
    "            ### Sample elements randomly from a given list of ids, no replacement\n",
    "            train_subsampler = SubsetRandomSampler(train_ids)\n",
    "            val_subsampler = SubsetRandomSampler(val_ids)\n",
    "            \n",
    "            ### Define data loaders for training and validation in current fold\n",
    "            train_loader = DataLoader(dataset = training_data, batch_size = 25, sampler = train_subsampler)\n",
    "            val_loader = DataLoader(dataset = training_data, batch_size = 25, sampler = val_subsampler)\n",
    "            \n",
    "            ### Initialize network\n",
    "            network1 = DistilBert\n",
    "            network2 = CNN\n",
    "            if torch.cuda.is_available():\n",
    "                network1.cuda()\n",
    "                network1 = nn.DataParallel(network1, list(range(2)))\n",
    "                \n",
    "                network2.cuda()\n",
    "                network2 = nn.DataParallel(network2, list(range(2)))\n",
    "                \n",
    "                device = 'cuda'\n",
    "            \n",
    "            ### Initialize optimizer\n",
    "            optimizer1 = transformers.Adafactor(\n",
    "                network1.parameters(),\n",
    "                lr=None,  # when using warm up and relative step, LR is auto determined\n",
    "                eps=(1e-30, 1e-3),\n",
    "                clip_threshold=1.0,\n",
    "                decay_rate=-0.8, #0.8\n",
    "                beta1=None, # <- used for L1 regularization\n",
    "                weight_decay=0.000002, # L2 regularization, to prevent overfitting  (beta2)\n",
    "                relative_step=True,\n",
    "                scale_parameter=True, # https://github.com/pytorch/pytorch/issues/25081 this setting keeps the gradients from reaching 0 (using the clip threshold) (if this is enabled, must modify in training)\n",
    "                warmup_init=True\n",
    "            )\n",
    "                        \n",
    "            optimizer2 = optim.Adam(network2.parameters(), lr=learning_rate)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer2, mode = 'min', factor = 0.1, patience = 5)\n",
    "            \n",
    "            \n",
    "            ### Create lists of values at the end of each epoch for each fold\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            train_f1_mic = []\n",
    "            train_f1_mac = []\n",
    "            train_prec_mic = []\n",
    "            train_prec_mac = []\n",
    "            train_rec_mic = []\n",
    "            train_rec_mac = []\n",
    "            \n",
    "            val_loss = []\n",
    "            val_acc = []\n",
    "            val_f1_mic = []\n",
    "            val_f1_mac = []\n",
    "            val_prec_mic = []\n",
    "            val_prec_mac = []\n",
    "            val_rec_mic = []\n",
    "            val_rec_mac = []\n",
    "            \n",
    "            \n",
    "            ### Train network\n",
    "            for epoch in range(n_epochs):\n",
    "                \n",
    "                ### Hold training predictions and targets\n",
    "                train_output = np.empty((0,22), int)\n",
    "                train_all_targets = np.empty((0,22), int)\n",
    "                \n",
    "                val_output = np.empty((0,22), int)\n",
    "                val_all_targets = np.empty((0,22), int)\n",
    "                \n",
    "                \n",
    "                ### Train ###\n",
    "                network1.train()\n",
    "                network2.train()\n",
    "                \n",
    "                train_running_loss = 0.0\n",
    "                \n",
    "                batch_number = 0\n",
    "                for i, data in enumerate(train_loader):\n",
    "                    \n",
    "                    images, text, hate, sent, targets = data[0].to(device), data[1], data[2].to(device), data[3].to(device), data[4].float().to(device)\n",
    "                    \n",
    "                    optimizer1.zero_grad()\n",
    "                    optimizer2.zero_grad()\n",
    "                    \n",
    "                    \n",
    "                    ids = []\n",
    "                    mask = []\n",
    "\n",
    "                    for j in text:   \n",
    "                        inputs = tokenizer.encode_plus(\n",
    "                                j, \n",
    "                                None,\n",
    "                                add_special_tokens = True,    \n",
    "                                max_length= 512,\n",
    "                                padding = \"max_length\",\n",
    "                                pad_to_max_length = True,\n",
    "                                return_token_type_ids= False)\n",
    "\n",
    "                        ids.append(inputs['input_ids'])\n",
    "                        mask.append(inputs['attention_mask'])\n",
    "\n",
    "                    ids = torch.from_numpy(np.array(ids)).to(device)\n",
    "                    mask = torch.from_numpy(np.array(mask)).to(device)\n",
    "\n",
    "                    distil_output = network1(ids, mask, hate, sent)\n",
    "\n",
    "                    output = network2(images, distil_output)\n",
    "\n",
    "                    \n",
    "                    loss = criterion(output, targets) \n",
    "                    train_running_loss += loss.item()\n",
    "                                        \n",
    "                    ### Append output\n",
    "                    train_output = np.vstack((train_output, ((output > 0.5).cpu().numpy().astype('int'))))\n",
    "                    train_all_targets = np.vstack((train_all_targets, targets.cpu().numpy().astype('int')))\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer1.step()\n",
    "                    optimizer2.step()\n",
    "                    \n",
    "                    \n",
    "                ### Calculate metrics and append\n",
    "                train_loss.append(train_running_loss/len(train_loader.dataset))\n",
    "                train_acc.append(accuracy_score(train_all_targets, train_output))\n",
    "                train_f1_mic.append(f1_score(train_all_targets, train_output, average = 'micro'))\n",
    "                train_f1_mac.append(f1_score(train_all_targets, train_output, average = 'macro'))\n",
    "                train_prec_mic.append(precision_score(train_all_targets, train_output, average = 'micro'))\n",
    "                train_prec_mac.append(precision_score(train_all_targets, train_output, average = 'macro'))\n",
    "                train_rec_mic.append(recall_score(train_all_targets, train_output, average = 'micro'))\n",
    "                train_rec_mac.append(recall_score(train_all_targets, train_output, average = 'macro'))\n",
    "                \n",
    "                \n",
    "                ### Validate###\n",
    "                network1.eval()\n",
    "                network2.eval()\n",
    "                \n",
    "                val_running_loss = 0.0\n",
    "\n",
    "                                \n",
    "                for i, data in enumerate(val_loader):\n",
    "                    images, text, hate, sent, targets = data[0].to(device), data[1], data[2].to(device), data[3].to(device), data[4].float().to(device)\n",
    "                    \n",
    "                    ids = []\n",
    "                    mask = []\n",
    "                    \n",
    "                    for j in text:   \n",
    "                        inputs = tokenizer.encode_plus(\n",
    "                                j, \n",
    "                                None,\n",
    "                                add_special_tokens = True,    \n",
    "                                max_length= 512,\n",
    "                                padding = \"max_length\",\n",
    "                                pad_to_max_length = True,\n",
    "                                return_token_type_ids= False)\n",
    "\n",
    "                        ids.append(inputs['input_ids'])\n",
    "                        mask.append(inputs['attention_mask'])\n",
    "\n",
    "                    ids = torch.from_numpy(np.array(ids)).to(device)\n",
    "                    mask = torch.from_numpy(np.array(mask)).to(device)\n",
    "\n",
    "                    distil_output = network1(ids, mask, hate, sent)\n",
    "\n",
    "                    output = network2(images, distil_output)\n",
    "                    \n",
    "                    loss = criterion(output, targets)\n",
    "                    val_running_loss += loss.item()\n",
    "                    \n",
    "                    ### Append output\n",
    "                    val_output = np.vstack((val_output, ((output > 0.5).cpu().numpy().astype('int'))))\n",
    "                    val_all_targets = np.vstack((val_all_targets, targets.cpu().numpy().astype('int')))\n",
    "\n",
    "                \n",
    "                ### Calculate metrics and append\n",
    "                val_loss.append(val_running_loss/len(val_loader.dataset))\n",
    "                val_acc.append(accuracy_score(val_all_targets, val_output))\n",
    "                val_f1_mic.append(f1_score(val_all_targets, val_output, average = 'micro'))\n",
    "                val_f1_mac.append(f1_score(val_all_targets, val_output, average = 'macro'))\n",
    "                val_prec_mic.append(precision_score(val_all_targets, val_output, average = 'micro'))\n",
    "                val_prec_mac.append(precision_score(val_all_targets, val_output, average = 'macro'))\n",
    "                val_rec_mic.append(recall_score(val_all_targets, val_output, average = 'micro'))\n",
    "                val_rec_mac.append(recall_score(val_all_targets, val_output, average = 'macro'))\n",
    "                \n",
    "                \n",
    "                ### Save model with the lowest validation loss\n",
    "                if val_f1_mic[epoch] > val_f1_mic_max:\n",
    "                    print('Validation F1 Micro Score Increased ({:.6f} --> {:.6f}).  Saving model ...\\n'.format(\n",
    "                    val_f1_mic_max,\n",
    "                    val_f1_mic[epoch]))\n",
    "                    torch.save(network1.state_dict(), 'BestCnnRnnDBModels/DB_' + model_name[:-3] + '.pt')\n",
    "                    torch.save(network2.state_dict(), 'BestCnnRnnDBModels/' + model_name +'.pt')\n",
    "                    val_f1_mic_max = val_f1_mic[epoch]\n",
    "                    \n",
    "                    ### Set current best metrics\n",
    "                    best_train_loss = train_loss[epoch]\n",
    "                    best_train_acc = train_acc[epoch]\n",
    "                    best_train_f1_mic = train_f1_mic[epoch]\n",
    "                    best_train_f1_mac = train_f1_mac[epoch]\n",
    "                    best_train_prec_mic = train_prec_mic[epoch]\n",
    "                    best_train_prec_mac = train_prec_mac[epoch]\n",
    "                    best_train_rec_mic = train_rec_mic[epoch]\n",
    "                    best_train_rec_mac = train_rec_mac[epoch]\n",
    "\n",
    "                    best_val_acc = val_acc[epoch]\n",
    "                    best_val_loss = val_loss[epoch]\n",
    "#                     best_val_f1_mic = val_f1_mic[epoch]\n",
    "                    best_val_f1_mac = val_f1_mac[epoch]\n",
    "                    best_val_prec_mic = val_prec_mic[epoch]\n",
    "                    best_val_prec_mac = val_prec_mac[epoch]\n",
    "                    best_val_rec_mic = val_rec_mic[epoch]\n",
    "                    best_val_rec_mac = val_rec_mac[epoch]\n",
    "\n",
    "                    best_fold = fold + 1\n",
    "                    best_epoch = epoch + 1\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                ### Display summary for epoch\n",
    "                print('Epoch {} \\tLearning Rate: {} \\tTime (min): {}'.format(epoch+1, get_lr(optimizer2), round((time.time()-start)/60, 2)))\n",
    "                print('Train Loss: {} \\tValidation Loss: {}'. format(round(train_loss[epoch], 4),\n",
    "                                                                     round(val_loss[epoch], 4)))\n",
    "                print('Train Accuracy: {} \\tValidation Accuracy: {}'.format(round(train_acc[epoch], 4),\n",
    "                                                                            round(val_acc[epoch], 4)))\n",
    "                print('Train F1 Mirco: {} \\tValidation F1 Micro: {}'.format(round(train_f1_mic[epoch], 4),\n",
    "                                                                            round(val_f1_mic[epoch], 4)))\n",
    "                print('Train F1 Marco: {} \\tValidation F1 Macro: {}'.format(round(train_f1_mac[epoch], 4),\n",
    "                                                                            round(val_f1_mac[epoch], 4)))\n",
    "                print('Train Precision Mirco: {} \\tValidation Precision Micro: {}'.format(round(train_prec_mic[epoch], 4),\n",
    "                                                                                          round(val_prec_mic[epoch], 4)))\n",
    "                print('Train Precision Marco: {} \\tValidation Precision Macro: {}'.format(round(train_prec_mac[epoch], 4),\n",
    "                                                                                          round(val_prec_mac[epoch], 4)))\n",
    "                print('Train Recall Mirco: {} \\tValidation Recall Micro: {}'.format(round(train_rec_mic[epoch], 4),\n",
    "                                                                                    round(val_rec_mic[epoch], 4)))\n",
    "                print('Train Recall Marco: {} \\tValidation Recall Macro: {}\\n'.format(round(train_rec_mac[epoch], 4),\n",
    "                                                                                    round(val_rec_mac[epoch], 4)))\n",
    "                \n",
    "                \n",
    "                ### Update learning rate if needed\n",
    "                scheduler.step(val_loss[epoch])\n",
    "                \n",
    "                \n",
    "                \n",
    "            ### Display summary graph of fold\n",
    "            fig, (ax1, ax3) = plt.subplots(1,2, figsize = (20,6))\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ln1 = ax1.plot(np.arange(start = 1, stop = n_epochs + 1), train_loss, label = 'Train Loss')\n",
    "            ln2 = ax1.plot(np.arange(start = 1, stop = n_epochs + 1), val_loss, label = 'Val Loss')\n",
    "            \n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.set_ylabel('Accuracy')\n",
    "            ln3 = ax2.plot(np.arange(start = 1, stop = n_epochs + 1), train_acc, marker = 'o', label = 'Train Acc')\n",
    "            ln4 = ax2.plot(np.arange(start = 1, stop = n_epochs + 1), val_acc, marker = 'o', label = 'Val Acc')\n",
    "            \n",
    "            lns1 = ln1 + ln2 + ln3 + ln4\n",
    "            labs1 = [l.get_label() for l in lns1]\n",
    "            \n",
    "            ax3.set_xlabel('Epoch')\n",
    "            ax3.set_ylabel('Score')\n",
    "            ln5 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_f1_mic, marker = 'v', label = 'Train F1 Micro')\n",
    "            ln6 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_f1_mic, marker = 'v', label = 'Val F1 Micro')\n",
    "            ln7 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_f1_mac, marker = '^', label = 'Train F1 Macro')\n",
    "            ln8 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_f1_mac, marker = '^', label = 'Val F1 Micro')\n",
    "            ln9 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_prec_mic, marker = 'd', label = 'Train Prec. Micro')\n",
    "            ln10 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_prec_mic, marker = 'd', label = 'Val Prec. Micro')\n",
    "            ln11 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_prec_mac, marker = 'X', label = 'Train Prec. Macro')\n",
    "            ln12 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_prec_mac, marker = 'X', label = 'Val Prec. Macro')\n",
    "            ln13 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_rec_mic, marker = 'P', label = 'Train Rec. Micro')\n",
    "            ln14 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_rec_mic, marker = 'P', label = 'Val Rec. Micro')\n",
    "            ln15 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_rec_mac, marker = 's', label = 'Train Rec. Macro')\n",
    "            ln16 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_rec_mac, marker = 's', label = 'Val Rec. Macro')\n",
    "            \n",
    "            lns2 = ln5 + ln6 + ln7 + ln8 +  ln9 + ln10 + ln11 + ln12 + ln13 + ln14 + ln15 + ln16\n",
    "            labs2 = [l.get_label() for l in lns2]\n",
    "            \n",
    "            \n",
    "            ax1.legend(lns1, labs1, loc = 'upper left', bbox_to_anchor = (1.1,1))\n",
    "            ax3.legend(lns2, labs2, loc = 'upper left', bbox_to_anchor = (1.05,1))\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            fig.savefig('MultiModal_DependentLabels_500_1_0_TrainingSummary/' + model_name + '_FOLD' + str(fold+1) + '.png')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### Display metrics of the best model\n",
    "                \n",
    "        print('------------------------------------------------------------')\n",
    "        print('------------------------------------------------------------')\n",
    "        \n",
    "        print('\\nMetrics of Best Model:')\n",
    "        print('Fold: {} \\tEpoch: {}'.format(best_fold, best_epoch))\n",
    "        print('Train Loss: {} \\tValidation Loss: {}'. format(round(best_train_loss, 4),\n",
    "                                                             round(best_val_loss, 4)))\n",
    "        print('Train Accuracy: {} \\tValidation Accuracy: {}'.format(round(best_train_acc, 4),\n",
    "                                                                    round(best_val_acc, 4)))\n",
    "        print('Train F1 Mirco: {} \\tValidation F1 Micro: {}'.format(round(best_train_f1_mic, 4),\n",
    "                                                                    round(val_f1_mic_max, 4)))\n",
    "        print('Train F1 Marco: {} \\tValidation F1 Macro: {}'.format(round(best_train_f1_mac, 4),\n",
    "                                                                    round(best_val_f1_mac, 4)))\n",
    "        print('Train Precision Mirco: {} \\tValidation Precision Micro: {}'.format(round(best_train_prec_mic, 4),\n",
    "                                                                                  round(best_val_prec_mic, 4)))\n",
    "        print('Train Precision Marco: {} \\tValidation Precision Macro: {}'.format(round(best_train_prec_mac, 4),\n",
    "                                                                                  round(best_val_prec_mac, 4)))\n",
    "        print('Train Recall Mirco: {} \\tValidation Recall Micro: {}'.format(round(best_train_rec_mic, 4),\n",
    "                                                                            round(best_val_rec_mic, 4)))\n",
    "        print('Train Recall Marco: {} \\tValidation Recall Macro: {}'.format(round(best_train_rec_mac, 4),\n",
    "                                                                            round(best_val_rec_mac, 4)))\n",
    "        \n",
    "        \n",
    "        ### Return best metrics\n",
    "        return [best_fold, best_epoch, best_train_loss, best_train_acc, best_train_f1_mic, best_train_f1_mac, best_train_prec_mic, best_train_prec_mac, best_train_rec_mic, best_train_rec_mac,\n",
    "                best_val_loss, best_val_acc, val_f1_mic_max, best_val_f1_mac, best_val_prec_mic, best_val_prec_mac, best_val_rec_mic, best_val_rec_mac]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models: Hidden Size = 500, Number of Layers = 1, Dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_resnet18 = DistilBertClass()\n",
    "DB_resnet50 = DistilBertClass()\n",
    "DB_resnet101 = DistilBertClass()\n",
    "\n",
    "DB_densenet121 = DistilBertClass()\n",
    "DB_densenet169 = DistilBertClass()\n",
    "DB_densenet201 = DistilBertClass()\n",
    "\n",
    "DB_vgg11bn = DistilBertClass()\n",
    "DB_vgg16bn = DistilBertClass()\n",
    "DB_vgg19bn = DistilBertClass()\n",
    "\n",
    "resnet18LSTM_500_1_0 = ResNet18_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "resnet50LSTM_500_1_0 = ResNet50_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "resnet101LSTM_500_1_0 = ResNet101_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "\n",
    "densenet121LSTM_500_1_0 = DenseNet121_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "densenet169LSTM_500_1_0 = DenseNet169_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "densenet201LSTM_500_1_0 = DenseNet201_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "\n",
    "vgg11bnLSTM_500_1_0 = VGG11_BN_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "vgg16bnLSTM_500_1_0 = VGG16_BN_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)\n",
    "vgg19bnLSTM_500_1_0 = VGG19_BN_LSTM_DB(hiddenSize = 500, numLayers = 1, dpout = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18LSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = resnet18LSTM_500_1_0, DistilBert = DB_resnet18,\n",
    "                                                training_data = training_data, learning_rate = 0.01,\n",
    "                                                k_folds = 10, n_epochs = 30, model_name = 'resnet18LSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50LSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = resnet50LSTM_500_1_0, DistilBert = DB_resnet50, \n",
    "                                                training_data = training_data, learning_rate = 0.01, \n",
    "                                                k_folds = 10, n_epochs = 30, model_name = 'resnet50LSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101LSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = resnet101LSTM_500_1_0, DistilBert = DB_resnet101, \n",
    "                                                 training_data = training_data, learning_rate = 0.01,\n",
    "                                                 k_folds = 10, n_epochs = 30, model_name = 'resnet101LSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet121LSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = densenet121LSTM_500_1_0, DistilBert = DB_densenet121, \n",
    "                                                   training_data = training_data, learning_rate = 0.01, \n",
    "                                                   k_folds = 10, n_epochs = 30, model_name = 'densenet121LSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet169LSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = densenet169LSTM_500_1_0, DistilBert = DB_densenet169, \n",
    "                                                   training_data = training_data, learning_rate = 0.01, k_folds = 10, \n",
    "                                                   n_epochs = 30, model_name = 'densenet169LSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet201LSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = densenet201LSTM_500_1_0, DistilBert = DB_densenet201, \n",
    "                                                   training_data = training_data, learning_rate = 0.01, \n",
    "                                                   k_folds = 10, n_epochs = 30, model_name = 'densenet201LSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11bnLSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = vgg11bnLSTM_500_1_0, DistilBert = DB_vgg11bn, \n",
    "                                               training_data = training_data, learning_rate = 0.01, \n",
    "                                               k_folds = 10, n_epochs = 30, model_name = 'vgg11bnLSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16bnLSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = vgg16bnLSTM_500_1_0, DistilBert = DB_vgg16bn, \n",
    "                                               training_data = training_data, learning_rate = 0.01, \n",
    "                                               k_folds = 10, n_epochs = 30, model_name = 'vgg16bnLSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19bnLSTM_500_1_0_best = Kfold_train_CNN_RNN_DB(CNN = vgg19bnLSTM_500_1_0, DistilBert = DB_vgg19bn, \n",
    "                                               training_data = training_data, learning_rate = 0.01, \n",
    "                                               k_folds = 10, n_epochs = 30, model_name = 'vgg19bnLSTM_500_1_0_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Training Time (HR:M:S): ' + str(datetime.timedelta(hours = ((time.time() - START) / 60 / 60))).rsplit('.', 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDF = pd.DataFrame({\n",
    "    'ResNet18' : resnet18LSTM_500_1_0_best,\n",
    "    'ResNet50' : resnet50LSTM_500_1_0_best,\n",
    "    'ResNet101' : resnet101LSTM_500_1_0_best,\n",
    "    'DenseNet121' : densenet121LSTM_500_1_0_best,\n",
    "    'DenseNet169' : densenet169LSTM_500_1_0_best,\n",
    "    'DenseNet201' : densenet201LSTM_500_1_0_best,\n",
    "    'VGG11_BN' : vgg11bnLSTM_500_1_0_best,\n",
    "    'VGG16_BN' : vgg16bnLSTM_500_1_0_best,\n",
    "    'VGG19_BN' : vgg19bnLSTM_500_1_0_best\n",
    "})\n",
    "summaryDF.index = ['Fold', 'Epoch', 'Train Loss', 'Train Accuracy', 'Train F1 Micro', 'Train F1 Macro', 'Train Precision Micro', 'Train Precision Macro', 'Train Recall Micro', 'Train Recall Macro',\n",
    "                   'Val Loss', 'Val Accuracy', 'Val F1 Micro', 'Val F1 Macro', 'Val Precision Micro', 'Val Precision Macro', 'Val Recall Micro', 'Val Recall Macro']\n",
    "\n",
    "summaryDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Summary Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [\n",
    "    go.Bar(name = 'ResNet18', x = summaryDF.index[3:10], y = summaryDF['ResNet18'][3:10]),\n",
    "    go.Bar(name = 'ResNet50', x = summaryDF.index[3:10], y = summaryDF['ResNet50'][3:10]),\n",
    "    go.Bar(name = 'ResNet101', x = summaryDF.index[3:10], y = summaryDF['ResNet101'][3:10]),\n",
    "    go.Bar(name = 'DenseNet121', x = summaryDF.index[3:10], y = summaryDF['DenseNet121'][3:10]),\n",
    "    go.Bar(name = 'DenseNet169', x = summaryDF.index[3:10], y = summaryDF['DenseNet169'][3:10]),\n",
    "    go.Bar(name = 'DenseNet201', x = summaryDF.index[3:10], y = summaryDF['DenseNet201'][3:10]),\n",
    "    go.Bar(name = 'VGG11_BN', x = summaryDF.index[3:10], y = summaryDF['VGG11_BN'][3:10]),\n",
    "    go.Bar(name = 'VGG16_BN', x = summaryDF.index[3:10], y = summaryDF['VGG16_BN'][3:10]),\n",
    "    go.Bar(name = 'VGG19_BN', x = summaryDF.index[3:10], y = summaryDF['VGG19_BN'][3:10]),\n",
    "])\n",
    "fig.update_layout(barmode = 'group',\n",
    "                  title = 'Best Model Metrics Across Folds (Training) - Hidden Size = 500, NumLayers = 1, Dropout = 0 - With DistilBert',\n",
    "                  xaxis_title = 'Metrics',\n",
    "                  yaxis_title = 'Score',\n",
    "                  legend_title = 'Models')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [\n",
    "    go.Bar(name = 'ResNet18', x = summaryDF.index[11:], y = summaryDF['ResNet18'][11:]),\n",
    "    go.Bar(name = 'ResNet50', x = summaryDF.index[11:], y = summaryDF['ResNet50'][11:]),\n",
    "    go.Bar(name = 'ResNet101', x = summaryDF.index[11:], y = summaryDF['ResNet101'][11:]),\n",
    "    go.Bar(name = 'DenseNet121', x = summaryDF.index[11:], y = summaryDF['DenseNet121'][11:]),\n",
    "    go.Bar(name = 'DenseNet169', x = summaryDF.index[11:], y = summaryDF['DenseNet169'][11:]),\n",
    "    go.Bar(name = 'DenseNet201', x = summaryDF.index[11:], y = summaryDF['DenseNet201'][11:]),\n",
    "    go.Bar(name = 'VGG11_BN', x = summaryDF.index[11:], y = summaryDF['VGG11_BN'][11:]),\n",
    "    go.Bar(name = 'VGG16_BN', x = summaryDF.index[11:], y = summaryDF['VGG16_BN'][11:]),\n",
    "    go.Bar(name = 'VGG19_BN', x = summaryDF.index[11:], y = summaryDF['VGG19_BN'][11:]),\n",
    "])\n",
    "fig.update_layout(barmode = 'group',\n",
    "                  title = 'Best Model Metrics Across Folds (Validation) - Hidden Size = 500, NumLayers = 1, Dropout = 0 - With DistilBert',\n",
    "                  xaxis_title = 'Metrics',\n",
    "                  yaxis_title = 'Score',\n",
    "                  legend_title = 'Models')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
