{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-RNN Model Training, Dependent Labels\n",
    "## Author: Ian Scarff (iie728)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "import skimage\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Smears', 'Loaded Language', 'Name calling/Labeling', 'Glittering generalities (Virtue)',\n",
    "               'Appeal to (Strong) Emotions', 'Appeal to fear/prejudice', 'Transfer', 'Doubt',\n",
    "               'Exaggeration/Minimisation', 'Whataboutism', 'Slogans', 'Flag-waving',\n",
    "               \"Misrepresentation of Someone's Position (Straw Man)\", 'Causal Oversimplification',\n",
    "               'Thought-terminating clichÃ©', 'Black-and-white Fallacy/Dictatorship', 'Appeal to authority',\n",
    "               'Reductio ad hitlerum', 'Repetition', 'Obfuscation, Intentional vagueness, Confusion',\n",
    "               'Presenting Irrelevant Data (Red Herring)', 'Bandwagon']\n",
    "\n",
    "### Create Class Binarizer\n",
    "one_hot = MultiLabelBinarizer()\n",
    "one_hot.fit([classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomLoader import ImageLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageLoader(json_file = 'training_data.json', root_dir = 'Images',\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Resize(size = (224,224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ### Pixel range [-1,1]\n",
    "                           ]))\n",
    "\n",
    "testing_data = ImageLoader(json_file = 'testing_data.json', root_dir = 'Images',\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Resize(size = (224,224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ### Pixel range [-1,1]\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = training_data, batch_size = 25, shuffle = True)\n",
    "test_loader = DataLoader(dataset = testing_data, batch_size = 25, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN-RNN Architectures (Set Hidden Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet18_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(ResNet18_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet18 = models.resnet18(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = resnet18.fc.in_features\n",
    "        \n",
    "        resnet18.fc = Identity()\n",
    "        \n",
    "        for param in resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = resnet18\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)       \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet50_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(ResNet50_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet50 = models.resnet50(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = resnet50.fc.in_features\n",
    "        \n",
    "        resnet50.fc = Identity()\n",
    "        \n",
    "        for param in resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = resnet50\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)       \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet101-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet101_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(ResNet101_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet101 = models.resnet101(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = resnet101.fc.in_features\n",
    "        \n",
    "        resnet101.fc = Identity()\n",
    "        \n",
    "        for param in resnet101.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = resnet101\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet121-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet121_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(DenseNet121_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet121 = models.densenet121(pretrained = True)\n",
    "    \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = densenet121.classifier.in_features\n",
    "        \n",
    "        densenet121.classifier = Identity()\n",
    "\n",
    "        ### CNN Encoder\n",
    "        self.cnn = densenet121\n",
    "        \n",
    "        for param in densenet121.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "       \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet169-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet169_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(DenseNet169_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet169 = models.densenet169(pretrained = True)\n",
    "    \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = densenet169.classifier.in_features\n",
    "        \n",
    "        densenet169.classifier = Identity()\n",
    "        \n",
    "        for param in densenet169.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        ### CNN Encoder\n",
    "        self.cnn = densenet169\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "           \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet201-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet201_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(DenseNet201_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "               \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet201 = models.densenet201(pretrained = True)\n",
    "    \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = densenet201.classifier.in_features\n",
    "        \n",
    "        densenet201.classifier = Identity()\n",
    "        \n",
    "        for param in densenet201.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        ### CNN Encoder\n",
    "        self.cnn = densenet201\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG11_BN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG11_BN_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(VGG11_BN_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg11bn = models.vgg11_bn(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = vgg11bn.classifier[6].in_features\n",
    "        \n",
    "        vgg11bn.classifier[6] = Identity()\n",
    "        \n",
    "        for param in vgg11bn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg11bn\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16_BN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG16_BN_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(VGG16_BN_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg16bn = models.vgg16_bn(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = vgg16bn.classifier[6].in_features\n",
    "        \n",
    "        vgg16bn.classifier[6] = Identity()\n",
    "        \n",
    "        for param in vgg16bn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg16bn\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19_BN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG19_BN_LSTM(nn.Module):\n",
    "    def __init__(self, hiddenSize, numLayers, dpout):\n",
    "        super(VGG19_BN_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg19bn = models.vgg19_bn(pretrained = True)\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = vgg19bn.classifier[6].in_features\n",
    "        \n",
    "        vgg19bn.classifier[6] = Identity()\n",
    "        \n",
    "        for param in vgg19bn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg19bn\n",
    "        \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = hiddenSize, ### Output size for each hidden state\n",
    "                              num_layers = numLayers,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Shrink embeddings to hidden size\n",
    "        self.shrink = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(hiddenSize, 1)\n",
    "        \n",
    "        ### Initial weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Intialize weights\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform(self.shrink.weight)\n",
    "        self.shrink.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform(self.prediction_layer.weight)\n",
    "        self.prediction_layer.bias.data.fill_(0)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images)         \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "        h0 = torch.unsqueeze(self.shrink(image_emb), 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        ### Squeeze to remove extra deminsion\n",
    "        combined = torch.squeeze(combined, 2)\n",
    "        \n",
    "        ### Sigmoid activation\n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optim):\n",
    "    for param_group in optim.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function is used to train a cnn model\n",
    "def Kfold_train_CNN_RNN(model = None, training_data = None, learning_rate = None, k_folds = None, n_epochs = None, model_name = None):\n",
    "    \n",
    "    ### Check that all entries are valid\n",
    "    if ((model == None) or (training_data == None) or (model_name == None) or \n",
    "        (learning_rate == None) or (k_folds == None) or (n_epochs == None)):\n",
    "        print ('Enter all info.')\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Run K-Fold CV\n",
    "    else:\n",
    "        \n",
    "        device = 'cpu'\n",
    "\n",
    "        ### Set Loss Function and Optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        \n",
    "        #### Define the K-fold Cross Validator\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### Create values to hold the best model metrics across folds\n",
    "        val_f1_mic_max = 0 ### This determines best model\n",
    "        \n",
    "        best_train_loss = 0\n",
    "        best_train_acc = 0\n",
    "        best_train_f1_mic = 0\n",
    "        best_train_f1_mac = 0\n",
    "        best_train_prec_mic = 0\n",
    "        best_train_prec_mac = 0\n",
    "        best_train_rec_mic = 0\n",
    "        best_train_rec_mac = 0\n",
    "\n",
    "        best_val_acc = 0\n",
    "        best_val_loss = 0\n",
    "#         best_val_f1_mic = 0\n",
    "        best_val_f1_mac = 0\n",
    "        best_val_prec_mic = 0\n",
    "        best_val_prec_mac = 0\n",
    "        best_val_rec_mic = 0\n",
    "        best_val_rec_mac = 0\n",
    "        \n",
    "        best_fold = 0\n",
    "        best_epoch = 0\n",
    "        \n",
    "\n",
    "        \n",
    "        ### Start print\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        ### K-fold Cross Validation model evaluation\n",
    "        for fold, (train_ids, val_ids) in enumerate(kfold.split(training_data)):\n",
    "            \n",
    "            print('-------------------------------------------')\n",
    "            print('FOLD {}'.format(fold + 1))\n",
    "            print('-------------------------------------------')\n",
    "            \n",
    "            ### Sample elements randomly from a given list of ids, no replacement\n",
    "            train_subsampler = SubsetRandomSampler(train_ids)\n",
    "            val_subsampler = SubsetRandomSampler(val_ids)\n",
    "            \n",
    "            ### Define data loaders for training and validation in current fold\n",
    "            train_loader = DataLoader(dataset = training_data, batch_size = 25, sampler = train_subsampler)\n",
    "            val_loader = DataLoader(dataset = training_data, batch_size = 25, sampler = val_subsampler)\n",
    "            \n",
    "            ### Initialize network\n",
    "            network = model\n",
    "            if torch.cuda.is_available():\n",
    "                network.cuda()\n",
    "                network = nn.DataParallel(network, list(range(2)))\n",
    "                device = 'cuda'\n",
    "            \n",
    "            ### Initialize optimizer\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.1, patience = 5)\n",
    "            \n",
    "            \n",
    "            ### Create lists of values at the end of each epoch for each fold\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            train_f1_mic = []\n",
    "            train_f1_mac = []\n",
    "            train_prec_mic = []\n",
    "            train_prec_mac = []\n",
    "            train_rec_mic = []\n",
    "            train_rec_mac = []\n",
    "            \n",
    "            val_loss = []\n",
    "            val_acc = []\n",
    "            val_f1_mic = []\n",
    "            val_f1_mac = []\n",
    "            val_prec_mic = []\n",
    "            val_prec_mac = []\n",
    "            val_rec_mic = []\n",
    "            val_rec_mac = []\n",
    "            \n",
    "            \n",
    "            ### Train network\n",
    "            for epoch in range(n_epochs):\n",
    "                \n",
    "                ### Hold training predictions and targets\n",
    "                train_output = np.empty((0,22), int)\n",
    "                train_all_targets = np.empty((0,22), int)\n",
    "                \n",
    "                val_output = np.empty((0,22), int)\n",
    "                val_all_targets = np.empty((0,22), int)\n",
    "                \n",
    "                \n",
    "                ### Train ###\n",
    "                network.train()\n",
    "                \n",
    "                train_running_loss = 0.0\n",
    "                \n",
    "                batch_number = 0\n",
    "                for i, data in enumerate(train_loader):\n",
    "                    \n",
    "                    images, targets = data[0].to(device), data[1].float().to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    output = network(images)\n",
    "                    \n",
    "                    loss = criterion(output, targets) \n",
    "                    train_running_loss += loss.item()\n",
    "                                        \n",
    "                    ### Append output\n",
    "                    train_output = np.vstack((train_output, ((output > 0.5).cpu().numpy().astype('int'))))\n",
    "                    train_all_targets = np.vstack((train_all_targets, targets.cpu().numpy().astype('int')))\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                                        \n",
    "                    \n",
    "                ### Calculate metrics and append\n",
    "                train_loss.append(train_running_loss/len(train_loader.dataset))\n",
    "                train_acc.append(accuracy_score(train_all_targets, train_output))\n",
    "                train_f1_mic.append(f1_score(train_all_targets, train_output, average = 'micro'))\n",
    "                train_f1_mac.append(f1_score(train_all_targets, train_output, average = 'macro'))\n",
    "                train_prec_mic.append(precision_score(train_all_targets, train_output, average = 'micro'))\n",
    "                train_prec_mac.append(precision_score(train_all_targets, train_output, average = 'macro'))\n",
    "                train_rec_mic.append(recall_score(train_all_targets, train_output, average = 'micro'))\n",
    "                train_rec_mac.append(recall_score(train_all_targets, train_output, average = 'macro'))\n",
    "                \n",
    "                \n",
    "                ### Validate###\n",
    "                network.eval()\n",
    "                val_running_loss = 0.0\n",
    "\n",
    "                                \n",
    "                for i, data in enumerate(val_loader):\n",
    "                    images, targets = data[0].to(device), data[1].float().to(device)\n",
    "                    output = network(images)\n",
    "                    loss = criterion(output, targets)\n",
    "                    val_running_loss += loss.item()\n",
    "                    \n",
    "                    ### Append output\n",
    "                    val_output = np.vstack((val_output, ((output > 0.5).cpu().numpy().astype('int'))))\n",
    "                    val_all_targets = np.vstack((val_all_targets, targets.cpu().numpy().astype('int')))\n",
    "\n",
    "                \n",
    "                ### Calculate metrics and append\n",
    "                val_loss.append(val_running_loss/len(val_loader.dataset))\n",
    "                val_acc.append(accuracy_score(val_all_targets, val_output))\n",
    "                val_f1_mic.append(f1_score(val_all_targets, val_output, average = 'micro'))\n",
    "                val_f1_mac.append(f1_score(val_all_targets, val_output, average = 'macro'))\n",
    "                val_prec_mic.append(precision_score(val_all_targets, val_output, average = 'micro'))\n",
    "                val_prec_mac.append(precision_score(val_all_targets, val_output, average = 'macro'))\n",
    "                val_rec_mic.append(recall_score(val_all_targets, val_output, average = 'micro'))\n",
    "                val_rec_mac.append(recall_score(val_all_targets, val_output, average = 'macro'))\n",
    "                \n",
    "                \n",
    "                ### Save model with the lowest validation loss\n",
    "                if val_f1_mic[epoch] > val_f1_mic_max:\n",
    "                    print('Validation F1 Micro Score Increased ({:.6f} --> {:.6f}).  Saving model ...\\n'.format(\n",
    "                    val_f1_mic_max,\n",
    "                    val_f1_mic[epoch]))\n",
    "                    torch.save(network.state_dict(), 'BestCnnRnnModels_10folds/' + model_name +'.pt')\n",
    "                    val_f1_mic_max = val_f1_mic[epoch]\n",
    "                    \n",
    "                    ### Set current best metrics\n",
    "                    best_train_loss = train_loss[epoch]\n",
    "                    best_train_acc = train_acc[epoch]\n",
    "                    best_train_f1_mic = train_f1_mic[epoch]\n",
    "                    best_train_f1_mac = train_f1_mac[epoch]\n",
    "                    best_train_prec_mic = train_prec_mic[epoch]\n",
    "                    best_train_prec_mac = train_prec_mac[epoch]\n",
    "                    best_train_rec_mic = train_rec_mic[epoch]\n",
    "                    best_train_rec_mac = train_rec_mac[epoch]\n",
    "\n",
    "                    best_val_acc = val_acc[epoch]\n",
    "                    best_val_loss = val_loss[epoch]\n",
    "#                     best_val_f1_mic = val_f1_mic[epoch]\n",
    "                    best_val_f1_mac = val_f1_mac[epoch]\n",
    "                    best_val_prec_mic = val_prec_mic[epoch]\n",
    "                    best_val_prec_mac = val_prec_mac[epoch]\n",
    "                    best_val_rec_mic = val_rec_mic[epoch]\n",
    "                    best_val_rec_mac = val_rec_mac[epoch]\n",
    "\n",
    "                    best_fold = fold + 1\n",
    "                    best_epoch = epoch + 1\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                ### Display summary for epoch\n",
    "                print('Epoch {} \\tLearning Rate: {} \\tTime (min): {}'.format(epoch+1, get_lr(optimizer), round((time.time()-start)/60, 2)))\n",
    "                print('Train Loss: {} \\tValidation Loss: {}'. format(round(train_loss[epoch], 4),\n",
    "                                                                     round(val_loss[epoch], 4)))\n",
    "                print('Train Accuracy: {} \\tValidation Accuracy: {}'.format(round(train_acc[epoch], 4),\n",
    "                                                                            round(val_acc[epoch], 4)))\n",
    "                print('Train F1 Mirco: {} \\tValidation F1 Micro: {}'.format(round(train_f1_mic[epoch], 4),\n",
    "                                                                            round(val_f1_mic[epoch], 4)))\n",
    "                print('Train F1 Marco: {} \\tValidation F1 Macro: {}'.format(round(train_f1_mac[epoch], 4),\n",
    "                                                                            round(val_f1_mac[epoch], 4)))\n",
    "                print('Train Precision Mirco: {} \\tValidation Precision Micro: {}'.format(round(train_prec_mic[epoch], 4),\n",
    "                                                                                          round(val_prec_mic[epoch], 4)))\n",
    "                print('Train Precision Marco: {} \\tValidation Precision Macro: {}'.format(round(train_prec_mac[epoch], 4),\n",
    "                                                                                          round(val_prec_mac[epoch], 4)))\n",
    "                print('Train Recall Mirco: {} \\tValidation Recall Micro: {}'.format(round(train_rec_mic[epoch], 4),\n",
    "                                                                                    round(val_rec_mic[epoch], 4)))\n",
    "                print('Train Recall Marco: {} \\tValidation Recall Macro: {}\\n'.format(round(train_rec_mac[epoch], 4),\n",
    "                                                                                    round(val_rec_mac[epoch], 4)))\n",
    "                \n",
    "                \n",
    "                ### Update learning rate if needed\n",
    "                scheduler.step(val_loss[epoch])\n",
    "                \n",
    "                \n",
    "                \n",
    "            ### Display summary graph of fold\n",
    "            fig, (ax1, ax3) = plt.subplots(1,2, figsize = (20,6))\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ln1 = ax1.plot(np.arange(start = 1, stop = n_epochs + 1), train_loss, label = 'Train Loss')\n",
    "            ln2 = ax1.plot(np.arange(start = 1, stop = n_epochs + 1), val_loss, label = 'Val Loss')\n",
    "            \n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.set_ylabel('Accuracy')\n",
    "            ln3 = ax2.plot(np.arange(start = 1, stop = n_epochs + 1), train_acc, marker = 'o', label = 'Train Acc')\n",
    "            ln4 = ax2.plot(np.arange(start = 1, stop = n_epochs + 1), val_acc, marker = 'o', label = 'Val Acc')\n",
    "            \n",
    "            lns1 = ln1 + ln2 + ln3 + ln4\n",
    "            labs1 = [l.get_label() for l in lns1]\n",
    "            \n",
    "            ax3.set_xlabel('Epoch')\n",
    "            ax3.set_ylabel('Score')\n",
    "            ln5 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_f1_mic, marker = 'v', label = 'Train F1 Micro')\n",
    "            ln6 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_f1_mic, marker = 'v', label = 'Val F1 Micro')\n",
    "            ln7 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_f1_mac, marker = '^', label = 'Train F1 Macro')\n",
    "            ln8 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_f1_mac, marker = '^', label = 'Val F1 Micro')\n",
    "            ln9 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_prec_mic, marker = 'd', label = 'Train Prec. Micro')\n",
    "            ln10 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_prec_mic, marker = 'd', label = 'Val Prec. Micro')\n",
    "            ln11 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_prec_mac, marker = 'X', label = 'Train Prec. Macro')\n",
    "            ln12 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_prec_mac, marker = 'X', label = 'Val Prec. Macro')\n",
    "            ln13 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_rec_mic, marker = 'P', label = 'Train Rec. Micro')\n",
    "            ln14 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_rec_mic, marker = 'P', label = 'Val Rec. Micro')\n",
    "            ln15 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), train_rec_mac, marker = 's', label = 'Train Rec. Macro')\n",
    "            ln16 = ax3.plot(np.arange(start = 1, stop = n_epochs + 1), val_rec_mac, marker = 's', label = 'Val Rec. Macro')\n",
    "            \n",
    "            lns2 = ln5 + ln6 + ln7 + ln8 +  ln9 + ln10 + ln11 + ln12 + ln13 + ln14 + ln15 + ln16\n",
    "            labs2 = [l.get_label() for l in lns2]\n",
    "            \n",
    "            \n",
    "            ax1.legend(lns1, labs1, loc = 'upper left', bbox_to_anchor = (1.1,1))\n",
    "            ax3.legend(lns2, labs2, loc = 'upper left', bbox_to_anchor = (1.05,1))\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### Display metrics of the best model\n",
    "                \n",
    "        print('------------------------------------------------------------')\n",
    "        print('------------------------------------------------------------')\n",
    "        \n",
    "        print('\\nMetrics of Best Model:')\n",
    "        print('Fold: {} \\tEpoch: {}'.format(best_fold, best_epoch))\n",
    "        print('Train Loss: {} \\tValidation Loss: {}'. format(round(best_train_loss, 4),\n",
    "                                                             round(best_val_loss, 4)))\n",
    "        print('Train Accuracy: {} \\tValidation Accuracy: {}'.format(round(best_train_acc, 4),\n",
    "                                                                    round(best_val_acc, 4)))\n",
    "        print('Train F1 Mirco: {} \\tValidation F1 Micro: {}'.format(round(best_train_f1_mic, 4),\n",
    "                                                                    round(val_f1_mic_max, 4)))\n",
    "        print('Train F1 Marco: {} \\tValidation F1 Macro: {}'.format(round(best_train_f1_mac, 4),\n",
    "                                                                    round(best_val_f1_mac, 4)))\n",
    "        print('Train Precision Mirco: {} \\tValidation Precision Micro: {}'.format(round(best_train_prec_mic, 4),\n",
    "                                                                                  round(best_val_prec_mic, 4)))\n",
    "        print('Train Precision Marco: {} \\tValidation Precision Macro: {}'.format(round(best_train_prec_mac, 4),\n",
    "                                                                                  round(best_val_prec_mac, 4)))\n",
    "        print('Train Recall Mirco: {} \\tValidation Recall Micro: {}'.format(round(best_train_rec_mic, 4),\n",
    "                                                                            round(best_val_rec_mic, 4)))\n",
    "        print('Train Recall Marco: {} \\tValidation Recall Macro: {}'.format(round(best_train_rec_mac, 4),\n",
    "                                                                            round(best_val_rec_mac, 4)))\n",
    "        \n",
    "        \n",
    "        ### Return best metrics\n",
    "        return [best_fold, best_epoch, best_train_loss, best_train_acc, best_train_f1_mic, best_train_f1_mac, best_train_prec_mic, best_train_prec_mac, best_train_rec_mic, best_train_rec_mac,\n",
    "                best_val_loss, best_val_acc, val_f1_mic_max, best_val_f1_mac, best_val_prec_mic, best_val_prec_mac, best_val_rec_mic, best_val_rec_mac]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models: Hidden Size = 700, Number of Layers = 1, Dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18LSTM_700_1_0 = ResNet18_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "resnet50LSTM_700_1_0 = ResNet50_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "resnet101LSTM_700_1_0 = ResNet101_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "\n",
    "densenet121LSTM_700_1_0 = DenseNet121_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "densenet169LSTM_700_1_0 = DenseNet169_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "densenet201LSTM_700_1_0 = DenseNet201_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "\n",
    "vgg11bnLSTM_700_1_0 = VGG11_BN_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "vgg16bnLSTM_700_1_0 = VGG16_BN_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)\n",
    "vgg19bnLSTM_700_1_0 = VGG19_BN_LSTM(hiddenSize = 700, numLayers = 1, dpout = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18LSTM_700_1_0_best = Kfold_train_CNN_RNN(model = resnet18LSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'resnet18LSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50LSTM_700_1_0_best = Kfold_train_CNN_RNN(model = resnet50LSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'resnet50LSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101LSTM_700_1_0_best = Kfold_train_CNN_RNN(model = resnet101LSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'resnet101LSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet121LSTM_700_1_0_best = Kfold_train_CNN_RNN(model = densenet121LSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'densenet121LSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet169LSTM_700_1_0_best = Kfold_train_CNN_RNN(model = densenet169LSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'densenet169LSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet201LSTM_700_1_0_best = Kfold_train_CNN_RNN(model = densenet201LSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'densenet201LSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11bnLSTM_700_1_0_best = Kfold_train_CNN_RNN(model = vgg11bnLSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'vgg11bnLSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16bnLSTM_700_1_0_best = Kfold_train_CNN_RNN(model = vgg16bnLSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'vgg16bnLSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19bnLSTM_700_1_0_best = Kfold_train_CNN_RNN(model = vgg19bnLSTM_700_1_0, training_data = training_data, learning_rate = 0.01, k_folds = 10, n_epochs = 30, model_name = 'vgg19bnLSTM_700_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Training Time (HR:M:S): ' + str(datetime.timedelta(hours = ((time.time() - START) / 60 / 60))).rsplit('.', 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDF = pd.DataFrame({\n",
    "    'ResNet18' : resnet18LSTM_700_1_0_best,\n",
    "    'ResNet50' : resnet50LSTM_700_1_0_best,\n",
    "    'ResNet101' : resnet101LSTM_700_1_0_best,\n",
    "    'DenseNet121' : densenet121LSTM_700_1_0_best,\n",
    "    'DenseNet169' : densenet169LSTM_700_1_0_best,\n",
    "    'DenseNet201' : densenet201LSTM_700_1_0_best,\n",
    "    'VGG11_BN' : vgg11bnLSTM_700_1_0_best,\n",
    "    'VGG16_BN' : vgg16bnLSTM_700_1_0_best,\n",
    "    'VGG19_BN' : vgg19bnLSTM_700_1_0_best\n",
    "})\n",
    "summaryDF.index = ['Fold', 'Epoch', 'Train Loss', 'Train Accuracy', 'Train F1 Micro', 'Train F1 Macro', 'Train Precision Micro', 'Train Precision Macro', 'Train Recall Micro', 'Train Recall Macro',\n",
    "                   'Val Loss', 'Val Accuracy', 'Val F1 Micro', 'Val F1 Macro', 'Val Precision Micro', 'Val Precision Macro', 'Val Recall Micro', 'Val Recall Macro']\n",
    "\n",
    "summaryDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Summary Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [\n",
    "    go.Bar(name = 'ResNet18', x = summaryDF.index[3:10], y = summaryDF['ResNet18'][3:10]),\n",
    "    go.Bar(name = 'ResNet50', x = summaryDF.index[3:10], y = summaryDF['ResNet50'][3:10]),\n",
    "    go.Bar(name = 'ResNet101', x = summaryDF.index[3:10], y = summaryDF['ResNet101'][3:10]),\n",
    "    go.Bar(name = 'DenseNet121', x = summaryDF.index[3:10], y = summaryDF['DenseNet121'][3:10]),\n",
    "    go.Bar(name = 'DenseNet169', x = summaryDF.index[3:10], y = summaryDF['DenseNet169'][3:10]),\n",
    "    go.Bar(name = 'DenseNet201', x = summaryDF.index[3:10], y = summaryDF['DenseNet201'][3:10]),\n",
    "    go.Bar(name = 'VGG11_BN', x = summaryDF.index[3:10], y = summaryDF['VGG11_BN'][3:10]),\n",
    "    go.Bar(name = 'VGG16_BN', x = summaryDF.index[3:10], y = summaryDF['VGG16_BN'][3:10]),\n",
    "    go.Bar(name = 'VGG19_BN', x = summaryDF.index[3:10], y = summaryDF['VGG19_BN'][3:10]),\n",
    "])\n",
    "fig.update_layout(barmode = 'group',\n",
    "                  title = 'Best Model Metrics Across Folds (Training) - Hidden Size = 700, NumLayers = 1, Dropout = 0',\n",
    "                  xaxis_title = 'Metrics',\n",
    "                  yaxis_title = 'Score',\n",
    "                  legend_title = 'Models')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data = [\n",
    "    go.Bar(name = 'ResNet18', x = summaryDF.index[11:], y = summaryDF['ResNet18'][11:]),\n",
    "    go.Bar(name = 'ResNet50', x = summaryDF.index[11:], y = summaryDF['ResNet50'][11:]),\n",
    "    go.Bar(name = 'ResNet101', x = summaryDF.index[11:], y = summaryDF['ResNet101'][11:]),\n",
    "    go.Bar(name = 'DenseNet121', x = summaryDF.index[11:], y = summaryDF['DenseNet121'][11:]),\n",
    "    go.Bar(name = 'DenseNet169', x = summaryDF.index[11:], y = summaryDF['DenseNet169'][11:]),\n",
    "    go.Bar(name = 'DenseNet201', x = summaryDF.index[11:], y = summaryDF['DenseNet201'][11:]),\n",
    "    go.Bar(name = 'VGG11_BN', x = summaryDF.index[11:], y = summaryDF['VGG11_BN'][11:]),\n",
    "    go.Bar(name = 'VGG16_BN', x = summaryDF.index[11:], y = summaryDF['VGG16_BN'][11:]),\n",
    "    go.Bar(name = 'VGG19_BN', x = summaryDF.index[11:], y = summaryDF['VGG19_BN'][11:]),\n",
    "])\n",
    "fig.update_layout(barmode = 'group',\n",
    "                  title = 'Best Model Metrics Across Folds (Validation) - Hidden Size = 700, NumLayers = 1, Dropout = 0',\n",
    "                  xaxis_title = 'Metrics',\n",
    "                  yaxis_title = 'Score',\n",
    "                  legend_title = 'Models')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
