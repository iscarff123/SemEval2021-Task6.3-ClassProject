{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json \n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hatesonar import Sonar # This is the hate speech detection library; it is based on bert\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_object(filename):\n",
    "    with open(file, \"r\", encoding='utf-8') as read_file:\n",
    "        json_array = json.load(read_file)\n",
    "    json_data = []    \n",
    "    #parse the data\n",
    "    for item in json_array:\n",
    "        details = {\"id\":None, \"labels\":None, \"text\":None}\n",
    "        details['id'] = item['id']\n",
    "        try: \n",
    "            details['labels'] = item['labels']\n",
    "        except KeyError: \n",
    "            details['labels'] = []         \n",
    "        details['text'] = item['text']\n",
    "        json_data.append(details)\n",
    "\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "   # text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    #remove html\n",
    "   # text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text)\n",
    "    \n",
    "    #remove emoji\n",
    "   # text = ''.join(c for c in text if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    \n",
    "    # remove numbers\n",
    "    # text = re.sub('[0-9]+', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def hate_speech_classifier(df, Class, hate, offensive, neither):\n",
    "    for i in df['text']:\n",
    "        sonar_dict = sonar.ping(text=i)\n",
    "        Class.append(list(sonar_dict.values())[1])\n",
    "        hate.append(list(list(sonar_dict.values())[2][0].values())[1])\n",
    "        offensive.append(list(list(sonar_dict.values())[2][1].values())[1])\n",
    "        neither.append(list(list(sonar_dict.values())[2][2].values())[1])\n",
    "\n",
    "\n",
    "def sentiment_classifier(df):\n",
    "    for i,text in enumerate(df['text']):\n",
    "        result = sentimentanalyzer(text)[0]\n",
    "        df.loc[[i],'sentiment_class'] = result['label']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "lst_file_path=[]\n",
    "\n",
    "lst_file_path.append(\"../data/training_data_task3.txt\")\n",
    "\n",
    "lst_file_path.append(\"../data/validation_data_task3.txt\")\n",
    "\n",
    "\n",
    "# List of keys \n",
    "dataset = [\"training\", \"validation\"] \n",
    "# empty dictionary\n",
    "dic_datasets =  dict.fromkeys(dataset, pd.DataFrame()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading../data/training_data_task3.txt\n",
      "loading../data/validation_data_task3.txt\n"
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(lst_file_path):\n",
    "    print('loading'+ file)\n",
    "    dic_datasets[dataset[i]] = pd.DataFrame(extract_json_object(extract_json_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.DataFrame(dic_datasets['training'][['id','labels','text']])\n",
    "df_training.labels = df_training.labels.apply(lambda y: ['no_class'] if len(y)==0 else y)\n",
    "\n",
    "df_val = pd.DataFrame(dic_datasets['validation'][['id','labels','text']])\n",
    "df_val.labels = df_val.labels.apply(lambda y: ['no_class'] if len(y)==0 else y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auxilary features (hate speech indicator and sentiment )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neobo\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\neobo\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\neobo\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\neobo\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Sonar Hate Speech Detection\n",
    "sonar = Sonar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither               659\n",
       "offensive_language     60\n",
       "hate_speech             8\n",
       "Name: hate_speech_class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_class = []\n",
    "hate = []\n",
    "offensive = []\n",
    "neither = []\n",
    "\n",
    "#Function calling \n",
    "hate_speech_classifier(df_training, hate_speech_class, hate, offensive, neither)\n",
    "\n",
    "# Prepare columns to add the scores later\n",
    "df_training[\"hate_speech_class\"] = hate_speech_class\n",
    "#df_training[\"hate\"] = hate\n",
    "#df_training[\"offensive\"] = offensive\n",
    "#df_training[\"neither\"] = neither\n",
    "df_training.hate_speech_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither               120\n",
       "offensive_language     17\n",
       "hate_speech             3\n",
       "Name: hate_speech_class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_class = []\n",
    "hate = []\n",
    "offensive = []\n",
    "neither = []\n",
    "\n",
    "hate_speech_classifier(df_val, hate_speech_class, hate, offensive, neither)\n",
    "\n",
    "# Prepare columns to add the scores later\n",
    "df_val[\"hate_speech_class\"] = hate_speech_class\n",
    "\n",
    "#df_val[\"hate\"] = hate\n",
    "#df_val[\"offensive\"] = offensive\n",
    "#df_val[\"neither\"] = neither\n",
    "\n",
    "df_val.hate_speech_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis using distillbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentanalyzer = pipeline(\"sentiment-analysis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither               659\n",
       "offensive_language     60\n",
       "hate_speech             8\n",
       "Name: hate_speech_class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_class = []\n",
    "hate = []\n",
    "offensive = []\n",
    "neither = []\n",
    "\n",
    "#Function calling \n",
    "hate_speech_classifier(df_training, hate_speech_class, hate, offensive, neither)\n",
    "\n",
    "# Prepare columns to add the scores later\n",
    "df_training[\"hate_speech_class\"] = hate_speech_class\n",
    "#df_training[\"hate\"] = hate\n",
    "#df_training[\"offensive\"] = offensive\n",
    "#df_training[\"neither\"] = neither\n",
    "df_training.hate_speech_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither               120\n",
       "offensive_language     17\n",
       "hate_speech             3\n",
       "Name: hate_speech_class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_class = []\n",
    "hate = []\n",
    "offensive = []\n",
    "neither = []\n",
    "\n",
    "hate_speech_classifier(df_val, hate_speech_class, hate, offensive, neither)\n",
    "\n",
    "# Prepare columns to add the scores later\n",
    "df_val[\"hate_speech_class\"] = hate_speech_class\n",
    "\n",
    "#df_val[\"hate\"] = hate\n",
    "#df_val[\"offensive\"] = offensive\n",
    "#df_val[\"neither\"] = neither\n",
    "\n",
    "df_val.hate_speech_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis using distillbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentanalyzer = pipeline(\"sentiment-analysis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sentiment\n",
    "df_training = sentiment_classifier(df_training)\n",
    "df_val = sentiment_classifier(df_val)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot encode auxilary variables\n",
    "df_training = pd.get_dummies(df_training, columns =[\"hate_speech_class\",\"sentiment_class\"])\n",
    "df_val = pd.get_dummies(df_val, columns =[\"hate_speech_class\",\"sentiment_class\"])\n",
    "\n",
    "# hot encode multi - labels (dependant variable)\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "df_concat_labels = pd.concat([df_training.pop('labels'), df_val.pop('labels')])\n",
    "concat_labels = df_training.join(pd.DataFrame.sparse.from_spmatrix(\n",
    "                    mlb.fit_transform(df_concat_labels),\n",
    "                    index=df_concat_labels.index,\n",
    "                    columns=mlb.classes_))\n",
    "\n",
    "\n",
    "df_training = concat_labels[0:len(df_training)]\n",
    "df_training.reset_index(inplace=True)\n",
    "\n",
    "df_val = concat_labels[len(df_training):]\n",
    "df_val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech_class_hate_speech</th>\n",
       "      <th>hate_speech_class_neither</th>\n",
       "      <th>hate_speech_class_offensive_language</th>\n",
       "      <th>sentiment_class_NEGATIVE</th>\n",
       "      <th>sentiment_class_POSITIVE</th>\n",
       "      <th>Appeal to (Strong) Emotions</th>\n",
       "      <th>Appeal to authority</th>\n",
       "      <th>...</th>\n",
       "      <th>Obfuscation, Intentional vagueness, Confusion</th>\n",
       "      <th>Presenting Irrelevant Data (Red Herring)</th>\n",
       "      <th>Reductio ad hitlerum</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Smears</th>\n",
       "      <th>Thought-terminating cliché</th>\n",
       "      <th>Transfer</th>\n",
       "      <th>Whataboutism</th>\n",
       "      <th>no_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>The most costly errors in all of history\\n\\nWo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>The most costly errors in all of history\\n\\nWo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>366_batch_2</td>\n",
       "      <td>MY PARENTS WERE KILLED AS A RESULT OF A GUN FR...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>366_batch_2</td>\n",
       "      <td>MY PARENTS WERE KILLED AS A RESULT OF A GUN FR...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>VOTE IT OUT\\nVOTE IT OUT\\n\\nHE SAID IT WASN'T ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>582</td>\n",
       "      <td>431_batch_2</td>\n",
       "      <td>Did you know that every tire comes with a preb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>583</td>\n",
       "      <td>66</td>\n",
       "      <td>UN\\n\\nNew York UN Office Recruits Paramilitary...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>584</td>\n",
       "      <td>281_batch_2</td>\n",
       "      <td>Make AOC Bartend Again.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>585</td>\n",
       "      <td>110_batch_2</td>\n",
       "      <td>\"It affects virtually nobody. It's an amazing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>586</td>\n",
       "      <td>282_batch_2</td>\n",
       "      <td>THE MAYOR OF MINNEAPOLIS WANTS 55 MILLION DOLL...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index           id                                               text  \\\n",
       "0        0          182  The most costly errors in all of history\\n\\nWo...   \n",
       "1        0          182  The most costly errors in all of history\\n\\nWo...   \n",
       "2        1  366_batch_2  MY PARENTS WERE KILLED AS A RESULT OF A GUN FR...   \n",
       "3        1  366_batch_2  MY PARENTS WERE KILLED AS A RESULT OF A GUN FR...   \n",
       "4        2          148  VOTE IT OUT\\nVOTE IT OUT\\n\\nHE SAID IT WASN'T ...   \n",
       "..     ...          ...                                                ...   \n",
       "722    582  431_batch_2  Did you know that every tire comes with a preb...   \n",
       "723    583           66  UN\\n\\nNew York UN Office Recruits Paramilitary...   \n",
       "724    584  281_batch_2                          Make AOC Bartend Again.\\n   \n",
       "725    585  110_batch_2  \"It affects virtually nobody. It's an amazing ...   \n",
       "726    586  282_batch_2  THE MAYOR OF MINNEAPOLIS WANTS 55 MILLION DOLL...   \n",
       "\n",
       "     hate_speech_class_hate_speech  hate_speech_class_neither  \\\n",
       "0                                0                          1   \n",
       "1                                0                          1   \n",
       "2                                0                          1   \n",
       "3                                0                          1   \n",
       "4                                0                          1   \n",
       "..                             ...                        ...   \n",
       "722                              0                          0   \n",
       "723                              0                          1   \n",
       "724                              0                          1   \n",
       "725                              0                          1   \n",
       "726                              0                          1   \n",
       "\n",
       "     hate_speech_class_offensive_language  sentiment_class_NEGATIVE  \\\n",
       "0                                       0                         1   \n",
       "1                                       0                         1   \n",
       "2                                       0                         1   \n",
       "3                                       0                         1   \n",
       "4                                       0                         1   \n",
       "..                                    ...                       ...   \n",
       "722                                     1                         1   \n",
       "723                                     0                         1   \n",
       "724                                     0                         1   \n",
       "725                                     0                         0   \n",
       "726                                     0                         1   \n",
       "\n",
       "     sentiment_class_POSITIVE  Appeal to (Strong) Emotions  \\\n",
       "0                           0                            0   \n",
       "1                           0                            1   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "..                        ...                          ...   \n",
       "722                         0                            0   \n",
       "723                         0                            1   \n",
       "724                         0                            0   \n",
       "725                         1                            0   \n",
       "726                         0                            0   \n",
       "\n",
       "     Appeal to authority  ...  Obfuscation, Intentional vagueness, Confusion  \\\n",
       "0                      0  ...                                              0   \n",
       "1                      0  ...                                              0   \n",
       "2                      0  ...                                              0   \n",
       "3                      0  ...                                              1   \n",
       "4                      0  ...                                              0   \n",
       "..                   ...  ...                                            ...   \n",
       "722                    0  ...                                              0   \n",
       "723                    0  ...                                              0   \n",
       "724                    0  ...                                              0   \n",
       "725                    0  ...                                              0   \n",
       "726                    0  ...                                              0   \n",
       "\n",
       "     Presenting Irrelevant Data (Red Herring)  Reductio ad hitlerum  \\\n",
       "0                                           0                     0   \n",
       "1                                           0                     0   \n",
       "2                                           0                     0   \n",
       "3                                           0                     0   \n",
       "4                                           0                     0   \n",
       "..                                        ...                   ...   \n",
       "722                                         0                     0   \n",
       "723                                         0                     0   \n",
       "724                                         0                     0   \n",
       "725                                         0                     0   \n",
       "726                                         0                     0   \n",
       "\n",
       "     Repetition  Slogans  Smears  Thought-terminating cliché  Transfer  \\\n",
       "0             0        0       1                           0         1   \n",
       "1             0        0       0                           0         0   \n",
       "2             0        0       0                           0         0   \n",
       "3             0        0       0                           0         0   \n",
       "4             1        1       1                           0         0   \n",
       "..          ...      ...     ...                         ...       ...   \n",
       "722           0        0       0                           0         0   \n",
       "723           0        1       0                           0         0   \n",
       "724           0        1       1                           0         0   \n",
       "725           0        0       1                           0         0   \n",
       "726           0        0       0                           0         0   \n",
       "\n",
       "     Whataboutism  no_class  \n",
       "0               0         0  \n",
       "1               1         0  \n",
       "2               0         0  \n",
       "3               1         0  \n",
       "4               0         0  \n",
       "..            ...       ...  \n",
       "722             0         0  \n",
       "723             0         0  \n",
       "724             0         0  \n",
       "725             0         0  \n",
       "726             0         0  \n",
       "\n",
       "[727 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.text\n",
    "        \n",
    "        self.hate = dataframe[['hate_speech_class_hate_speech','hate_speech_class_neither', 'hate_speech_class_offensive_language']].to_numpy()\n",
    "        self.sentiment = dataframe[['sentiment_class_NEGATIVE','sentiment_class_POSITIVE']].to_numpy()\n",
    "        \n",
    "        self.targets = self.data[[\n",
    "                                    'Appeal to authority',\n",
    "                                    'Appeal to fear/prejudice',\n",
    "                                    'Black-and-white Fallacy/Dictatorship',\n",
    "                                    'Causal Oversimplification',\n",
    "                                    'Doubt',\n",
    "                                    'Exaggeration/Minimisation',\n",
    "                                    'Flag-waving',\n",
    "                                    'Glittering generalities (Virtue)',\n",
    "                                    'Loaded Language',\n",
    "                                    'Misrepresentation of Someone\\'s Position (Straw Man)',\n",
    "                                    'Name calling/Labeling',\n",
    "                                    'Obfuscation, Intentional vagueness, Confusion',\n",
    "                                    'Presenting Irrelevant Data (Red Herring)',\n",
    "                                    'Reductio ad hitlerum',\n",
    "                                    'Repetition',\n",
    "                                    'Slogans',\n",
    "                                    'Smears',\n",
    "                                    'Thought-terminating cliché',\n",
    "                                    'Whataboutism',\n",
    "                                    'Bandwagon',\n",
    "                                    'Transfer',\n",
    "                                    'Appeal to (Strong) Emotions'\n",
    "                                ]].to_numpy()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print(index)\n",
    "        #print(self.comment_text.index)\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        # inputs = self.tokenizer.encode_plus(\n",
    "        #    comment_text,\n",
    "        #    None,\n",
    "        #    add_special_tokens=True,\n",
    "        #    truncation=True,\n",
    "        #    max_length=self.max_len,\n",
    "        #    pad_to_max_length=True,\n",
    "        #    #padding=True,\n",
    "        #    #padding='longest',\n",
    "        #    return_token_type_ids=True\n",
    "        # )\n",
    "        #inputs = tokenizer.encode_plus(\n",
    "        #            comment_text, \n",
    "        #            add_special_tokens = True,    \n",
    "        #            truncation = False, \n",
    "        #            max_length=self.max_len,\n",
    "        #            padding = \"max_length\",\n",
    "                    #padding_side='right',\n",
    "                   # return_attention_mask = True, \n",
    "        #            return_tensors = \"pt\",\n",
    "        #            return_token_type_ids=True,    \n",
    "        #)\n",
    "        \n",
    "        inputs = tokenizer.encode_plus(\n",
    "                    comment_text, \n",
    "                    text_pair = None,\n",
    "                    add_special_tokens = True,    \n",
    "                    max_length=self.max_len,\n",
    "                    padding = \"max_length\",\n",
    "                    pad_to_max_length = True,\n",
    "                    return_token_type_ids=True,\n",
    "                    truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
    "            'hate': torch.tensor(self.hate[index], dtype=torch.long), \n",
    "            'sentiment': torch.tensor(self.sentiment[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "def create_data_loader_kfold(df_kf, df_val, trn_ids, tst_ids):\n",
    "    print('Original Train Dataset: ' + str(len(df_kf)))\n",
    "    \n",
    "    cust_Dataset_train = CustomDataset(df_kf, tokenizer, MAX_LEN)\n",
    "    cust_Dataset_val = CustomDataset(df_val, tokenizer, MAX_LEN)\n",
    "    \n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    kfold_train_subsampler = torch.utils.data.SubsetRandomSampler(trn_ids)\n",
    "    kfold_test_subsampler = torch.utils.data.SubsetRandomSampler(tst_ids)\n",
    "    \n",
    "    val_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                    'shuffle': True,\n",
    "                    'num_workers': 0\n",
    "                    }\n",
    "    \n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    kfold_trainloader = torch.utils.data.DataLoader(\n",
    "                      cust_Dataset_train, \n",
    "                      batch_size=VALID_BATCH_SIZE, sampler=kfold_train_subsampler)\n",
    "    kfold_testloader = torch.utils.data.DataLoader(\n",
    "                      cust_Dataset_train,\n",
    "                      batch_size=VALID_BATCH_SIZE, sampler=kfold_test_subsampler)\n",
    "    \n",
    "    valloader = DataLoader(cust_Dataset_val, **val_params)\n",
    "    \n",
    "\n",
    "    print(\"KFOLD CROSSVALIDATION TRAIN Dataset: {}\".format(len(kfold_trainloader) * kfold_trainloader.batch_size))\n",
    "    print(\"KFOLD CROSSVALIDATION TEST Dataset: {}\".format(len(kfold_testloader) * kfold_trainloader.batch_size))\n",
    "    print(\"VALIDATION Dataset: {}\".format(len(valloader) * valloader.batch_size))\n",
    "    \n",
    "    \n",
    "    return kfold_trainloader, kfold_testloader, valloader\n",
    "     \n",
    "\n",
    "def create_data_loader(train_dataset,test_dataset):\n",
    "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "    print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "    \n",
    "    training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "    testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)\n",
    "    dataset_size = len(train_dataset)\n",
    "    \n",
    "    train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "    test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                    'shuffle': True,\n",
    "                    'num_workers': 0\n",
    "                    }\n",
    "\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "    return training_loader, testing_loader, dataset_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testing_loader):\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    #track variables\n",
    "    true_labels,pred_labels = [],[]\n",
    "\n",
    "    # Predict\n",
    "    for _, data in enumerate(testing_loader, 0):\n",
    "        #print(_)\n",
    "        \n",
    "        #prepare data to feed into model\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        \n",
    "        hate = data['hate'].to(device, dtype = torch.long)\n",
    "        sent = data['sentiment'\n",
    "                   ].to(device, dtype = torch.long)\n",
    "                \n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "        \n",
    "       \n",
    "        with torch.no_grad():\n",
    "           \n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, model_output_object = model(ids, mask, None, hate, sent)\n",
    "            b_logit_pred = outputs\n",
    "            pred_label = b_logit_pred\n",
    "\n",
    "            b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "            pred_label = pred_label.to('cpu').numpy()\n",
    "            targets = targets.to('cpu').numpy()\n",
    "\n",
    "        #tokenized_texts.append(b_input_ids)\n",
    "        #logit_preds.append(b_logit_pred)\n",
    "        true_labels.append(targets)\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "    # Flatten outputs\n",
    "    #tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "    # print(true_labels)\n",
    "    # print(pred_labels)\n",
    "    pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "    # Converting flattened binary values to boolean values\n",
    "    true_bools = [tl==1 for tl in targets]\n",
    "    \n",
    "    return true_labels, true_bools, pred_labels, model_output_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
