{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-RNN Model Training, Dependent Labels\n",
    "## Author: Ian Scarff (iie728)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "import skimage\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['Smears', 'Loaded Language', 'Name calling/Labeling', 'Glittering generalities (Virtue)',\n",
    "               'Appeal to (Strong) Emotions', 'Appeal to fear/prejudice', 'Transfer', 'Doubt',\n",
    "               'Exaggeration/Minimisation', 'Whataboutism', 'Slogans', 'Flag-waving',\n",
    "               \"Misrepresentation of Someone's Position (Straw Man)\", 'Causal Oversimplification',\n",
    "               'Thought-terminating clich√©', 'Black-and-white Fallacy/Dictatorship', 'Appeal to authority',\n",
    "               'Reductio ad hitlerum', 'Repetition', 'Obfuscation, Intentional vagueness, Confusion',\n",
    "               'Presenting Irrelevant Data (Red Herring)', 'Bandwagon']\n",
    "\n",
    "### Create Class Binarizer\n",
    "one_hot = MultiLabelBinarizer()\n",
    "one_hot.fit([classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomLoader import ImageLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ImageLoader(json_file = 'training_data.json', root_dir = 'Images',\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Resize(size = (224,224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ### Pixel range [-1,1]\n",
    "                           ]))\n",
    "\n",
    "testing_data = ImageLoader(json_file = 'testing_data.json', root_dir = 'Images',\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Resize(size = (224,224)),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ### Pixel range [-1,1]\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = training_data, batch_size = 25, shuffle = True)\n",
    "test_loader = DataLoader(dataset = testing_data, batch_size = 25, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN-RNN Architectures (Set Hidden Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet18_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(ResNet18_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet18\n",
    "        resnet18 = models.resnet18(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        resnet18 = nn.Sequential(*list(resnet18.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = resnet18\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 512\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet50_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(ResNet50_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet50\n",
    "        resnet50 = models.resnet50(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        resnet50 = nn.Sequential(*list(resnet50.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = resnet50\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 2048\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet101-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class ResNet101_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(ResNet101_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import ResNet101\n",
    "        resnet101 = models.resnet101(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        resnet101 = nn.Sequential(*list(resnet101.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in resnet101.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = resnet101\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 2048\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet101-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet121_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(DenseNet121_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet101\n",
    "        densenet121 = models.densenet121(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        densenet121 = nn.Sequential(*list(densenet121.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in densenet121.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = densenet121\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 1024\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet169-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet169_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(DenseNet169_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet169\n",
    "        densenet169 = models.densenet169(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        densenet169 = nn.Sequential(*list(densenet169.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in densenet169.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = densenet169\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 1664\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet201-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class DenseNet201_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(DenseNet201_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        \n",
    "        ### Import DenseNet201\n",
    "        densenet201 = models.densenet201(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        densenet201 = nn.Sequential(*list(densenet201.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in densenet201.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = densenet201\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 1920\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG11_BN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG11_BN_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(VGG11_BN_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg11bn = models.vgg11_bn(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        vgg11bn = nn.Sequential(*list(vgg11bn.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in vgg11bn.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg11bn\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 25088\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16_BN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG16_BN_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(VGG16_BN_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg16bn = models.vgg16_bn(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        vgg16bn = nn.Sequential(*list(vgg16bn.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in vgg16bn.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg16bn\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 25088\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19_BN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Class\n",
    "class VGG19_BN_LSTM(nn.Module):\n",
    "    def __init__(self, dpout):\n",
    "        super(VGG19_BN_LSTM, self).__init__()\n",
    "        \n",
    "        ### Number of labels\n",
    "        self.num_labels = 22\n",
    "        \n",
    "        ### Import VGG11-BN\n",
    "        vgg19bn = models.vgg19_bn(pretrained = True)\n",
    "        \n",
    "        ### Remove classifier\n",
    "        vgg19bn = nn.Sequential(*list(vgg19bn.children())[:-1])\n",
    "        \n",
    "        ### Freeze parameters\n",
    "        for param in vgg19bn.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "        ### CNN Encoder\n",
    "        self.cnn = vgg19bn\n",
    "        \n",
    "        ### CNN output size\n",
    "        self.cnn_output_size = 25088\n",
    "            \n",
    "        \n",
    "        ### Create LSTM decoder\n",
    "        self.lstm = nn.LSTM(input_size = 1, \n",
    "                              hidden_size = self.cnn_output_size, ### Output size for each hidden state\n",
    "                              num_layers = 1,\n",
    "                              dropout = dpout, ### Dropout Rate,\n",
    "                              batch_first = True\n",
    "                             )\n",
    "        \n",
    "        \n",
    "        ### Convert image representation to lstm hidden size\n",
    "#         self.linear_image_to_lstm = nn.Linear(self.cnn_output_size, hiddenSize)\n",
    "        \n",
    "        ### Prediction layer\n",
    "        self.prediction_layer = nn.Linear(self.cnn_output_size, 1)\n",
    "        \n",
    "    \n",
    "    ### Forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        ### Pass images to CNN encoder\n",
    "        image_emb = self.cnn(images) \n",
    "        \n",
    "        \n",
    "        ### Flatten Image embeddings\n",
    "        image_emb = image_emb.view(-1, self.cnn_output_size)\n",
    "        \n",
    "        \n",
    "        ### Prep intial hidden state and cell state\n",
    "#         h0 = torch.unsqueeze(self.linear_image_to_lstm(image_emb), 0)\n",
    "        h0 = torch.unsqueeze(image_emb, 0)\n",
    "        c0 = torch.autograd.Variable(torch.zeros(h0.size(0), h0.size(1), h0.size(2)).cuda(), requires_grad = False)\n",
    "        \n",
    "        zero_input = torch.autograd.Variable(torch.zeros(image_emb.size(0), self.num_labels, 1).cuda(), requires_grad = False)\n",
    "        \n",
    "        ### Run through LSTM decoder\n",
    "        hidden_layers, _ = self.lstm(zero_input, (h0, c0))\n",
    "        \n",
    "        ### Unbind the hidden layers\n",
    "        unbound = torch.unbind(hidden_layers, 1)\n",
    "        \n",
    "        ### Run each hidden layer through the prediction linear layer\n",
    "        combined = [self.prediction_layer(i) for i in unbound]\n",
    "        \n",
    "        ### Stack predictions\n",
    "        combined = torch.stack(combined, 1)\n",
    "        \n",
    "        final = F.sigmoid(combined)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
